{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f40bdb",
   "metadata": {},
   "source": [
    "# 05_02: SOLUTION - Walk through of project solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.evaluation.qa.eval_chain import QAEvalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_neo4j import GraphCypherQAChain, Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "URI = os.getenv(\"NEO4J_URI\")\n",
    "USER = os.getenv(\"NEO4J_USER\")\n",
    "PWD = os.getenv(\"NEO4J_PWD\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = WikipediaLoader(query=\"Portugal\").load()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in text:\n",
    "    print(el.metadata['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(text)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e638fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(url=URI, username=USER, password=PWD)\n",
    "\n",
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bbfe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '../data/portugal text.pdf'\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_documents = llm_transformer.convert_to_graph_documents(chunks)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3992a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d065047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_graph = Neo4jGraph(url=URI, username=USER, password=PWD, enhanced_schema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fe91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to\n",
    "answer questions about Portugal.\n",
    "Convert the user's question based on the schema.\n",
    "\n",
    "When you are presented with query properties such as id's like \"rock pools\",\n",
    "be sure to convert the first letter to capital case, such as \"Rock Pools\"\n",
    "before you run the Cypher query.\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=enhanced_graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Tell me about the African Union?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04bee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to\n",
    "answer questions about Portugal.\n",
    "Convert the user's question based on the schema.\n",
    "\n",
    "When you are presented with query properties such as id's like \"rock pools\",\n",
    "be sure to convert the first letter to capital case, such as \"Rock Pools\"\n",
    "before you run the Cypher query.\n",
    "\n",
    "You also will want to remove words like \"the\" or \"an\" in front of entities.  For\n",
    "example, if I asked \"Tell me about the schengen area\", the entity is \"Schengen Area\"\n",
    "and NOT \"The Schengen Area\".\n",
    "\n",
    "For example, if I were to ask \"Tell me about the schengen area\",\" you should create\n",
    "a Cypher query that finds all nodes with the id \"Schengen Area\" and then find\n",
    "all nodes connected to those nodes and use those to forumulate your answer, like this:\n",
    "\n",
    "MATCH (a {{id: \"Schengen Area\"}})-[r]-(b)\n",
    "RETURN a, r, b\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=enhanced_graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25bae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Tell me about the African union?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63366fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Where can I go canyoning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcbfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to\n",
    "answer questions about Portugal.\n",
    "Convert the user's question based on the schema.\n",
    "\n",
    "When you are presented with query properties such as id's like \"rock pools\",\n",
    "be sure to convert the first letter to capital case, such as \"Rock Pools\"\n",
    "before you run the Cypher query.\n",
    "\n",
    "You also will want to remove words like \"the\" or \"an\" in front of entities.  For\n",
    "example, if I asked \"Tell me about the schengen area\", the entity is \"Schengen Area\"\n",
    "and NOT \"The Schengen Area\".\n",
    "\n",
    "For example, if I were to ask \"Tell me about the schengen area\",\" you should create\n",
    "a Cypher query that finds all nodes with the id \"Schengen Area\" and then find\n",
    "all nodes connected to those nodes and use those to forumulate your answer, like this:\n",
    "\n",
    "MATCH (a {{id: \"Schengen Area\"}})-[r]-(b)\n",
    "RETURN a, r, b\n",
    "\n",
    "Do NOT be very restrictive on the types of relationships you specify.  For example,\n",
    "if I ask \"Where can I go canyoning\", you should NOT specify the relationship type.\n",
    "Instead, use a Cypher query like this:\n",
    "\n",
    "MATCH (a {{id: \"Canyoning\"}})-[r]-(b:Place)\n",
    "RETURN a, r, b\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=enhanced_graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ecd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Where can I go on a cable car?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd15f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"query\": \"Where can I go kayaking?\",\n",
    "     \"answer\": \"Portugal, Mondego, or ZÃªzere\"},\n",
    "    {\"query\": \"How is Luis related to Isabella of Portugal?\", \n",
    "     \"answer\": \"They are siblings\"},\n",
    "    {\"query\": \"Where is Braga?\", \n",
    "     \"answer\": \"In the Minho Region\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0231363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_graph_rag(cypher_chain, eval_chain, examples):\n",
    "\n",
    "    # Generate predictions by querying the graph\n",
    "    predictions = []\n",
    "    for ex in examples:\n",
    "        graph_response = cypher_chain.invoke({\"query\": ex[\"query\"]})\n",
    "        predictions.append({\"result\": graph_response[\"result\"].strip()})\n",
    "\n",
    "    # Run evaluation\n",
    "    #eval_chain = QAEvalChain.from_llm(llm)\n",
    "    results = eval_chain.evaluate(examples, predictions)\n",
    "\n",
    "    # Print output\n",
    "    correct = 0\n",
    "    for i, res in enumerate(results):\n",
    "        print(f\"Query: {examples[i]['query']}\")\n",
    "        print(f\"Prediction from graph: {predictions[i]['result']}\")\n",
    "        print(f\"Gold answer: {examples[i]['answer']}\")\n",
    "        print(f\"Grade: {res['results']}\")\n",
    "        print(\"---\")\n",
    "        if res[\"results\"] == \"CORRECT\":\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(examples)\n",
    "    print(f\"Graph QA Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a76ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_graph_rag(cypher_chain, eval_chain, examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
